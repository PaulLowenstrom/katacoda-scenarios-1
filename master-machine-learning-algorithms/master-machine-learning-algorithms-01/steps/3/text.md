Before we dive into the details of linear regression, you may be asking yourself why we are
looking at this algorithm. Isn’t it a technique from statistics?
Machine learning, more specifically the field of predictive modeling is primarily concerned
with minimizing the error of a model or making the most accurate predictions possible, at the
expense of explainability. In applied machine learning we will borrow, reuse and steal algorithms
from many different fields, including statistics and use them towards these ends.
As such, linear regression was developed in the field of statistics and is studied as a model
for understanding the relationship between input and output numerical variables, but has
been borrowed by machine learning. It is both a statistical algorithm and a machine learning
algorithm. Next, let’s review some of the common names used to refer to a linear regression
model

#### Many Names of Linear Regression
When you start looking into linear regression, things can get very confusing. The reason is
because linear regression has been around for so long (more than 200 years). It has been studied
from every possible angle and often each angle has a new and different name.

Linear regression is a linear model, e.g. a model that assumes a linear relationship between
the input variables (x) and the single output variable (y). More specifically, that y can be
calculated from a linear combination of the input variables (x). When there is a single input
variable (x), the method is referred to as simple linear regression. When there are multiple
input variables, literature from statistics often refers to the method as multiple linear regression.

