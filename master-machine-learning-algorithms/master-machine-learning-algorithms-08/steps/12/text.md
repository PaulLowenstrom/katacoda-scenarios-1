We can now use this decision tree to make some predictions for all of the training instances.
But we have already done that when we calculated the Gini index above. Instead, letâ€™s classify
some new data generated for each class using the same distribution. Here is the test dataset:

![](https://github.com/fenago/katacoda-scenarios/raw/master/master-machine-learning-algorithms/master-machine-learning-algorithms-08/steps/12/1.JPG)

Using the decision tree with a single split at, X1 = 6:6422 we can classify the test instances
as follows:

![](https://github.com/fenago/katacoda-scenarios/raw/master/master-machine-learning-algorithms/master-machine-learning-algorithms-08/steps/12/2.JPG)
