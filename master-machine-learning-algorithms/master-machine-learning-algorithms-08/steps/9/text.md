The first step is to choose a split that will become the stump or root node of our decision tree.
We will start with the first candidate split point which is the X1 attribute and the value of X1
in the first instance: X1 = 2.7712.
- IF X1 < 2.7712 THEN **LEFT**
- IF X1 ≥ 2.7712 THEN **RIGHT**
Let’s apply this rule to each X1 value in our training dataset. Below is the answer we get
for each numbered instance in the dataset:

![](https://github.com/fenago/katacoda-scenarios/raw/master/master-machine-learning-algorithms/master-machine-learning-algorithms-08/steps/9/1.JPG)
