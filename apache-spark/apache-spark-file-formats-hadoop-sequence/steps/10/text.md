**Step 5:** Finally let us call the collect method and check the output from the RDD.

```hadoopRDD.collect()



As you can see from the screenshot above, we were successfully able to read the key value pairs from the MapReduce output.

Please try to read the data using new hadoop API as a lab challenge.

Task is complete!



SUMMARY

In this chapter we have looked at various file formats we can process using Spark. We have covered both the RDD API as well as DataSource API to read and write files from and to Spark.
In the labs, we have had our hands on using the various file formats we have learned using both the RDD API as well as DataSource API to read and write files from and to Spark.


