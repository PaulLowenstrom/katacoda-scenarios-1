Let’s design an experiment to evaluate a suite of standard classification algorithms on the
different views of the problem that we created
- Click the Experimenter button on the Weka GUI Chooser to launch the Weka
Experiment Environment
- Click New to start a new experiment
- In the Datasets pane click Add new and select the following 4 datasets:

– /root/Desktop/weka/examples/diabetes.arff (the raw dataset)
– diabetes-normalized.arff
– diabetes-standardized.arff
– diabetes-missing.arff
- In the Algorithms pane click Add new and add the following 8 classification algorithms:

– rulesZeroR
– bayesNaiveBayes
– functionsLogistic
– functionsSMO
– lazyIBk
– rulesPART
– treesREPTree
– treesJ48
- Select IBk in the list of algorithms and click the Edit selected button
- Change KNN from 1 to 3 and click the OK button to save the settings

![](https://github.com/fenago/katacoda-scenarios/raw/master/machine-learning-mastery-weka/machine-learning-mastery-weka-chapter-24/steps/images/154.png)

- Click on Run tab and click the Start button to run the experiment The experiment
should complete in just a few seconds
- Click on the Analyse tab Click the Experiment button to load the results from the
experiment

![](https://github.com/fenago/katacoda-scenarios/raw/master/machine-learning-mastery-weka/machine-learning-mastery-weka-chapter-24/steps/images/155.png)

- Click the Perform test button to perform a pairwise test-test comparing all of the
results to the results for ZeroR

![](https://github.com/fenago/katacoda-scenarios/raw/master/machine-learning-mastery-weka/machine-learning-mastery-weka-chapter-24/steps/images/24.1.png)

We can see that all of the algorithms are skillful on all of the views of the dataset compared
to ZeroR We can also see that our baseline for skill is 6511% accuracy Just looking at the raw
classification accuracies, we can see that the view of the dataset with missing values imputed
looks to have resulted in lower model accuracy in general It also looks like there is little
difference between the standardized and normalized results as compared to the raw results
other than a few fractions of percent It suggests we can probably stick with the raw dataset
Finally, it looks like Logistic regression may have achieved higher accuracy results than the
other algorithms, let’s check if the difference is significant
- Click the Select button for Test base and choose functionsLogistic Click the Perform
test button to rerun the analysis

![](https://github.com/fenago/katacoda-scenarios/raw/master/machine-learning-mastery-weka/machine-learning-mastery-weka-chapter-24/steps/images/24.2.png)

It does look like the logistic regression results are better than some of the other results, such
as IBk, PART, REPTree and ZeroR, but not statistically significantly different from NaiveBayes,
SMO or J48
- Check Show std deviations to show standard deviations
- Click the Select button for Displayed Columns and choose functionsLogistic, click
Select to accept the selection This will only show results for the logistic regression
algorithm
- Click Perform test to rerun the analysis

We now have a final result we can use to describe our model

![](https://github.com/fenago/katacoda-scenarios/raw/master/machine-learning-mastery-weka/machine-learning-mastery-weka-chapter-24/steps/images/24.3.png)

We can see that the estimated accuracy of the model on unseen data is 77.47% with a
standard deviation of 4.39%
- Close the Weka Experiment Environment
